{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from six.moves import cPickle\n",
    "from sklearn.preprocessing import normalize\n",
    "from main import get_data\n",
    "from sklearn.decomposition import PCA\n",
    "from myclasses import NNParameters\n",
    "#from train_models import perform_zero_prediction, perform_svd, perform_autoencoding, performance_lda, performance_knn\n",
    "#from plot import cost_function_plot, biplot, roc_plot\n",
    "from functions import rectifier, sigmoid, linear, cross_entropy, least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2882980047932029\n"
     ]
    }
   ],
   "source": [
    "from random import uniform\n",
    "print(uniform(0.7,1.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (1,2)\n",
    "b = (*a, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.33333333, -1.        , -1.66666667],\n",
       "       [-0.33333333,  5.        ,  2.33333333],\n",
       "       [ 1.66666667, -4.        , -0.66666667]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = np.array([[-1,4,1],[0,10,5],[2,1,2]])\n",
    "x_norm = (x - np.mean(x, axis=0))\n",
    "x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.33487957  1.94258902]\n",
      " [-5.49837434 -0.56871365]\n",
      " [ 4.16349477 -1.37387537]] \n",
      "\n",
      " [[-1.33333333 -1.         -1.66666667]\n",
      " [-0.33333333  5.          2.33333333]\n",
      " [ 1.66666667 -4.         -0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "U, D, VT = np.linalg.svd(x_norm)\n",
    "V_k = VT.T[:,0:2]\n",
    "z_k = np.dot(x_norm, V_k)\n",
    "x_k = np.dot(z_k, V_k.T)    \n",
    "print(z_k, '\\n\\n', x_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.33487957  1.94258902]\n",
      " [-5.49837434 -0.56871365]\n",
      " [ 4.16349477 -1.37387537]] \n",
      "\n",
      " [[ -1.00000000e+00   4.00000000e+00   1.00000000e+00]\n",
      " [  9.43689571e-16   1.00000000e+01   5.00000000e+00]\n",
      " [  2.00000000e+00   1.00000000e+00   2.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "z_k = pca.fit_transform(x)\n",
    "x_k = pca.inverse_transform(z_k)\n",
    "print(z_k, '\\n\\n', x_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in datafile with 55001 recipies and 381 ingredients.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bcer200r100l30r100r200s_0.0073'\n",
    "\n",
    "# Get the data.\n",
    "data, regions, ingredients = get_data()\n",
    "\n",
    "# Separate 1000 recipes for the recipe reconstruction phase\n",
    "data_reconstruct, data_autoencoder = data[:1000], data[1000:]\n",
    "_, regions_autoencoder = regions[:1000], regions[:1000]\n",
    "\n",
    "# Train a new autoencoder network if no network model is given and load⋅\n",
    "# the results of the autoencoder model, saved as pickle file\n",
    "if model_name is None:\n",
    "    model_name  = perform_autoencoding(data_autoencoder, p)\n",
    "with open('models/' + model_name + '.pkl', 'rb') as f:\n",
    "    output = cPickle.load(f)\n",
    "give_neurons, cost_train, cost_test, y_test, y_pred, run_time = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27  34  75  97 109 227 228 266 363]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_ingredients = 381\n",
    "rank_list = []\n",
    "for i in range(1):\n",
    "    \n",
    "    recipe = data_reconstruct[0].copy()\n",
    "\n",
    "    # Get ingredients and remove one randomly\n",
    "    ingredient_idxs = np.argwhere(recipe != 0).flatten()\n",
    "    removed_idx = np.random.choice(ingredient_idxs)\n",
    "    recipe[removed_idx] = 0\n",
    "    \n",
    "    # Get output layer of the autoencoder (needs 2D array as input)\n",
    "    reconstruction = give_neurons(recipe.reshape(1,-1))[-1][0]\n",
    "    \n",
    "    # Set ingredients of the recipe on -1  in reconstruction, \n",
    "    # we don't want those to in the ranking of our removed ingredient\n",
    "    reconstruction[recipe == 1] = -1\n",
    "\n",
    "    # Get the ingredient indexes sorted on reconstruction\n",
    "    reconstruction_with_idxs = zip(list(reconstruction), list(range(n_ingredients)))\n",
    "    _, sorted_idxs = zip(*sorted(reconstruction_with_idxs, reverse=True))\n",
    "    \n",
    "    # Get index of removed ingredient, add 1 for the rank.\n",
    "    rank = sorted_idxs.index(removed_idx) + 1\n",
    "    rank_list.append(rank)\n",
    "    \n",
    "    #print(removed_ingredient)\n",
    "    print(ingredient_idxs)\n",
    "    \n",
    "    #print(list(reconstruction))\n",
    "    #print(list(range(n_ingredients)))\n",
    "    print(*zip(*sorted(reconstruction_with_idxs)))\n",
    "    for i, j in reconstruction_with_idxs:\n",
    "        print(i,j)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, j in reconstruction_with_idxs:\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 1.1'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:4.2}'.format(1.123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_idx=np.argwhere(x!=0).flatten()\n",
    "remove = np.random.choice(non_zero_idx)\n",
    "x[remove] = 0\n",
    "remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[remove] = 0\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_idx=np.argwhere(x!=0).flatten()\n",
    "np.random.shuffle(non_zero_idx)\n",
    "random_pick=x[non_zero_idx]\n",
    "random_pick[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\r",
      "123\n"
     ]
    }
   ],
   "source": [
    "print('abc', end ='')\n",
    "print('\\r123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] aaaa\n",
      "\n",
      "[3 4] aaaa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in a:\n",
    "    print(row, 'aaaa')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameters():\n",
    "    '''Returns all the parameters of the network and gradient descent \n",
    "    as an object of the class NNParameters.'''\n",
    "\n",
    "    p = OrderedDict()\n",
    "\n",
    "    #Network settings\n",
    "    p['has_bias'] = True #True #Add bias to the layers or not\n",
    "    p['cost_fn'] = least_squares\n",
    "    p['activation_fn'] = [rectifier, rectifier, linear, rectifier, rectifier, sigmoid]\n",
    "    p['n_hidden_neurons'] = [200, 50, 2, 50, 200]\n",
    "\n",
    "    #Gradient descent parameters\n",
    "    p['test_size'] = 0.02 #Fraction to test the cost\n",
    "    p['eps_init'] = 0.05 #Half of the init range of the network param\n",
    "    p['batch_size'] = 10 #8 #Number of observations to use for gradient descent\n",
    "    p['alpha'] = 0.8 #Inertie coefficient.\n",
    "    p['delta'] = 0.5 #1 #2 #Learning rate\n",
    "    p['max_loops'] = 800 #Maximum number of loops over all the data\n",
    "    p['max_time'] = 18000 #Maximum time\n",
    "    p['low_cost'] = 0.0 #Lowest cost\n",
    "    p['cost_update_size'] = 10000 #Number of data to use before updating cost\n",
    "\n",
    "    return NNParameters(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(remove_NorthAmerican=False, standardize=False):\n",
    "    \"\"\" Import the data, return as numpy array. The ingredients names are⋅\n",
    "    stored in 'ingredients'.  'Data' contains the ingredients for each recipe,\n",
    "    coded as 0/1. 'Regions' contains the region of origin of the recipe. \"\"\"\n",
    "    \n",
    "    # Read in the data\n",
    "    df = pd.read_csv('datasets/ReceptenBinair_minimun2ingredients.csv', sep=';')\n",
    "    values = df.values\n",
    "    ingredients = np.array(df.columns)[1:]\n",
    "        \n",
    "    # Remove NorthAmerican recipe\n",
    "    if remove_NorthAmerican:\n",
    "        values = values[values[:,0] != 'NorthAmerican']                                                                    \n",
    "    \n",
    "    # Shuffle the data with seed\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(values)\n",
    "    \n",
    "    # Split into regions and the data containing ingredients coded as 0/1\n",
    "    regions = values[:,0]\n",
    "    data = values[:,1:].astype(int)\n",
    "    \n",
    "    # Standardize (In combination with remove NorthAmerican can create nan values!)\n",
    "    if standardize:\n",
    "        data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    \n",
    "    # Print dimensions and return regions, data and ingredients\n",
    "    out_text = 'Read in datafile with {} recipies and {} ingredients.'\n",
    "    print(out_text.format(len(data), len(ingredients)))\n",
    "    return regions, data, ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in datafile with 55001 recipies and 381 ingredients.\n"
     ]
    }
   ],
   "source": [
    "a,b,c = get_data(standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20848079, -0.00426401, -0.06351629, ..., -0.25572382,\n",
       "        -0.13848734, -0.14239131],\n",
       "       [-0.20848079, -0.00426401, -0.06351629, ..., -0.25572382,\n",
       "        -0.13848734, -0.14239131],\n",
       "       [-0.20848079, -0.00426401, -0.06351629, ...,  3.91046869,\n",
       "        -0.13848734, -0.14239131],\n",
       "       ..., \n",
       "       [-0.20848079, -0.00426401, -0.06351629, ..., -0.25572382,\n",
       "        -0.13848734, -0.14239131],\n",
       "       [-0.20848079, -0.00426401, -0.06351629, ..., -0.25572382,\n",
       "        -0.13848734, -0.14239131],\n",
       "       [-0.20848079, -0.00426401, -0.06351629, ...,  3.91046869,\n",
       "        -0.13848734, -0.14239131]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "almond                     0.199797\n",
       "angelica                   0.004264\n",
       "anise                      0.063261\n",
       "anise_seed                 0.039050\n",
       "apple                      0.203264\n",
       "apple_brandy               0.025218\n",
       "armagnac                   0.105235\n",
       "apricot                    0.014141\n",
       "artemisia                  0.015372\n",
       "artichoke                  0.083694\n",
       "asparagus                  0.088782\n",
       "avocado                    0.107737\n",
       "bacon                      0.193247\n",
       "baked_potato               0.012791\n",
       "balm                       0.007385\n",
       "banana                     0.131824\n",
       "barley                     0.064810\n",
       "bartlett_pear              0.020445\n",
       "basil                      0.252895\n",
       "bay                        0.161337\n",
       "bean                       0.182253\n",
       "beech                      0.004264\n",
       "beef                       0.282338\n",
       "beef_broth                 0.122202\n",
       "beef_liver                 0.013483\n",
       "beer                       0.072421\n",
       "beet                       0.064391\n",
       "bell_pepper                0.308137\n",
       "bergamot                   0.011281\n",
       "berry                      0.057114\n",
       "                             ...   \n",
       "thyme                      0.228545\n",
       "tomato                     0.384094\n",
       "tomato_juice               0.056477\n",
       "truffle                    0.030733\n",
       "tuna                       0.089384\n",
       "turkey                     0.125614\n",
       "turmeric                   0.148038\n",
       "turnip                     0.057429\n",
       "vanilla                    0.369346\n",
       "veal                       0.059891\n",
       "vegetable                  0.170836\n",
       "vegetable_oil              0.395890\n",
       "vinegar                    0.346380\n",
       "violet                     0.010444\n",
       "walnut                     0.217304\n",
       "wasabi                     0.043234\n",
       "watercress                 0.048931\n",
       "watermelon                 0.042813\n",
       "wheat                      0.484055\n",
       "wheat_bread                0.038583\n",
       "whiskey                    0.049115\n",
       "white_bread                0.081303\n",
       "white_wine                 0.194371\n",
       "whole_grain_wheat_flour    0.114052\n",
       "wine                       0.124629\n",
       "wood                       0.024487\n",
       "yam                        0.038817\n",
       "yeast                      0.240027\n",
       "yogurt                     0.135881\n",
       "zucchini                   0.139562\n",
       "dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/ReceptenBinair_minimun2ingredients.csv', sep=';')\n",
    "    \n",
    "#Remove empty ingredients\n",
    "#df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.std(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "knn accuracy: 0.6426\n",
      "5\n",
      "knn accuracy: 0.6593\n",
      "10\n",
      "knn accuracy: 0.6714\n",
      "12\n",
      "knn accuracy: 0.6691\n",
      "15\n",
      "knn accuracy: 0.6734\n",
      "18\n",
      "knn accuracy: 0.6759\n",
      "20\n",
      "knn accuracy: 0.6730\n",
      "30\n",
      "knn accuracy: 0.6741\n",
      "40\n",
      "knn accuracy: 0.6734\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data_filtered, test_size=0.3, random_state=42)\n",
    "regions_train, regions_test = train_test_split(regions_filtered, test_size=0.3, random_state=42)\n",
    "\n",
    "k = 15\n",
    "\n",
    "#data_train = data_train[:20000]\n",
    "#regions_train = regions_train[:20000]\n",
    "k_vals = [1,5,10,12,15,18,20,30,40]\n",
    "for k in k_vals:\n",
    "    print(k)\n",
    "    performance_knn(data_train, data_test, regions_train, regions_test, 'raw_knn', k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in datafile with 55001 recipies and 381 ingredients.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor k in range(1, 21, 10):\\n    performance_knn(data_train, data_test, regions_train, regions_test,\\n    'raw_knn', k)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for k in range(1, 21, 10):\n",
    "    performance_knn(data_train, data_test, regions_train, regions_test,\n",
    "    'raw_knn', k)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d118fd92aa35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32555\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "num = 32555\n",
    "for num in range(10001, 30000, 100):\n",
    "    for el, name in zip(list(df.iloc[num]), list(df.columns)):\n",
    "        if el:\n",
    "            print(name)\n",
    "    country = df.iloc[num].name\n",
    "    print(country)\n",
    "    if country != 'NorthAmerican':\n",
    "        input('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b1e78bdcd03c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Auto encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_name\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mperform_autoencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mgive_neurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#Auto encoder\n",
    "model_name  = perform_autoencoding(data, p) \n",
    "with open('models/' + model_name + '.pkl', 'rb') as f:\n",
    "    give_neurons, cost_train, cost_test, y_test, y_pred = cPickle.load(f)\n",
    "    \n",
    "#Get the bottleneck neurons of all data\n",
    "all_neurons = give_neurons(data.tolist())\n",
    "bottleneck_neurons = all_neurons[p.bottleneck_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in datafile with 55001 recipies and 381 ingredients.\n",
      "Performing singular value decomposition...\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#SVD\n",
    "p = get_parameters()\n",
    "data, regions, ingredients = get_data(centre=True, normalize=True)\n",
    "cost_svd, data_svd = perform_svd(data, p)\n",
    "\n",
    "#Make biplot of the bottleneck neurons and SVD reduction\n",
    "biplot(data_svd, regions, 'svd_{:0.4f}'.format(cost_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in datafile with 55001 recipies and 381 ingredients.\n"
     ]
    }
   ],
   "source": [
    "        biplot(bottleneck_neurons, regions, model_name)\n",
    "\n",
    "\n",
    "    #Filter out NorthAmerican for region prediction. NorthAmerican is \n",
    "    #contains recipes of all regions and dominates in numbers, \n",
    "    #which makes the prediction trivial\n",
    "    features_filtered = []\n",
    "    regions_filtered  = []\n",
    "    for features, region in zip(bottleneck_neurons, regions):\n",
    "        if region != 'NorthAmerican':\n",
    "            features_filtered.append(features)\n",
    "            regions_filtered.append(region)\n",
    "\n",
    "    biplot(features_filtered, regions_filtered, model_name + '_filter')\n",
    "\n",
    "    #Measure performance without NorthAmerican. Different train/test split \n",
    "    #than autoencoder training since the outcome variable 'region' wasn't used.\n",
    "    data_train, data_test = train_test_split(features_filtered, test_size=0.3,\n",
    "            random_state=42)\n",
    "    regions_train, regions_test = train_test_split(regions_filtered, \n",
    "            test_size=0.3, random_state=42)\n",
    "\n",
    "    #lda\n",
    "    regions_predicted = performance_lda(data_train, data_test, regions_train, \n",
    "            regions_test)\n",
    "    biplot(data_test, regions_predicted, 'lda_' + model_name)\n",
    "\n",
    "    #knn\n",
    "    regions_predicted = performance_knn(data_train, data_test, regions_train, \n",
    "            regions_test, model_name)\n",
    "    biplot(data_test, regions_predicted, 'knn_' + model_name)\n",
    "\n",
    "    input('Press any key to close figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def lin(x):\n",
    "    return x\n",
    "def lin_grad(x):\n",
    "    y = x.copy()\n",
    "    y.fill(1)\n",
    "    return y\n",
    "def rec(x):\n",
    "    y = x.copy()\n",
    "    y[y<0] = 0\n",
    "    return y\n",
    "def rec_grad(x):\n",
    "    return rec(x)/x\n",
    "def sigm(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def sigm_grad(x):\n",
    "    return sigm(x) * (1-sigm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-9.999999999,10,0.1)\n",
    "\n",
    "#box = dict(facecolor='yellow', pad=5, alpha=0.2)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0.2, wspace=0.6)\n",
    "\n",
    "funcs = [lin, lin_grad, sigm, sigm_grad, rec, rec_grad]\n",
    "yrange = [(-10,10),(-0.2,1.2),(-0.2,1.2),(-0.05,0.3),(-2,10),(-0.2,1.2)]\n",
    "\n",
    "for i, func in enumerate(funcs):\n",
    "    ax = fig.add_subplot(int('32' + str(i+1)))\n",
    "    ax.axhline(y=0, color='k')\n",
    "    ax.axvline(x=0, color='k')\n",
    "    ax.plot(x, func(x))\n",
    "    ax.set_ylim(*yrange[i])\n",
    "    if i < 4:\n",
    "        ax.set_xticklabels([])\n",
    "    if i == 0:\n",
    "        ax.set_title('Function')\n",
    "        ax.set_ylabel('Linear')\n",
    "    if i == 1:\n",
    "        ax.set_title('Function derivative')\n",
    "    if i == 2:\n",
    "        ax.set_ylabel('Sigmoid')\n",
    "    if i == 4:\n",
    "        ax.set_ylabel('Rectifier')\n",
    "\n",
    "plt.savefig('act_fns.eps', format='eps', dpi=1000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([50,30,20,10,5,4,3,3,3,2,2,2,1,1,1])*0.5\n",
    "\n",
    "# the histogram of the data\n",
    "plt.hist(x, facecolor='green', bins=15,normed=1)#50, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "plt.xlabel('Smarts')\n",
    "plt.ylabel('Probability')\n",
    "#plt.axis([40, 160, 0, 0.03])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
